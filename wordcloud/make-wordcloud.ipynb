{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashikita/qir-toolbox/blob/main/wordcloud/make-wordcloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jXNn0e4o7CN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "リポジトリ開設20周年サイト向け：ワードクラウド背景 “完全版” （Jupyter/Colab最適化）\n",
        "\n",
        "このスクリプトは、以下を一括で実現します。\n",
        " 1) 日本語フォントの自動インストール/検出（Colab対応）と指定\n",
        " 2) 日本語・英語混在タイトル（input.txt）からの形態素解析/トークン化\n",
        " 3) デザイン戦略に基づく配色（パレット/カラーマップ/カスタム）\n",
        " 4) バナー背景向けの推奨レイアウト（横書き寄り、語数調整、コントラスト制御）\n",
        " 5) 透過PNG、エッジフェード、セーフテキスト帯など背景素材向けの後処理\n",
        "\n",
        "―― デザイン戦略（背景用途のコツ / 実装ポイント）――\n",
        "- 背景は“控えめ”が美しい：彩度/コントラストを少し落とす、色数を絞る → PALETTE / COLOR_MODE\n",
        "- 横書き中心で整然と：prefer_horizontal を高く（= 1.0 に近く）\n",
        "- 読ませたい前景テキストの可読性確保：\n",
        "    - 透明度を下げる（ALPHA_ON_SAVE）\n",
        "    - エッジをフェード（APPLY_EDGE_FADE）\n",
        "    - セーフテキスト帯を敷く（ADD_SAFE_TITLE_BAND）\n",
        "- サイズは用途に合わせる：\n",
        "    - ヒーロー：2400x1200 / トップバナー：2400x800 / 細長帯：1600x300\n",
        "\n",
        "使い方：\n",
        "- 同じディレクトリに UTF-8 の input.txt（1行=1タイトル）を置いて実行してください。\n",
        "- Colab の場合、input.txt が無ければアップロードを促します。\n",
        "\n",
        "出力：\n",
        "- wordcloud.png               … 基本版（背景色あり/なしを選択）\n",
        "- wordcloud_transparent.png   … 透過版（TRANSPARENT_BG=True または ALPHA_ON_SAVE を適用）\n",
        "- wordcloud_faded.png         … エッジフェード版（背景により馴染む）\n",
        "- wordcloud_with_band.png     … セーフテキスト帯つき（上に大きな見出しを載せる前提）\n",
        "\n",
        "依存：\n",
        "- wordcloud, janome（任意/推奨）, tinysegmenter（任意）, pillow, numpy\n",
        "- Colab では Noto CJK フォントを自動導入\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# 設定ブロック（プロジェクトに合わせて調整してください）\n",
        "# ============================================================\n",
        "\n",
        "# 入出力\n",
        "INPUT_FILE = \"input.txt\"\n",
        "OUTPUT_PNG = \"wordcloud.png\"\n",
        "\n",
        "# キャンバスサイズ（下の PRESET を使うと自動設定）\n",
        "WC_WIDTH = 2400\n",
        "WC_HEIGHT = 800\n",
        "\n",
        "# プリセット：None / \"hero\" / \"banner\" / \"strip\"\n",
        "#  - \"hero\"   = 2400 x 1200\n",
        "#  - \"banner\" = 2400 x 800\n",
        "#  - \"strip\"  = 1600 x 300\n",
        "PRESET = \"banner\"\n",
        "\n",
        "# 背景設定\n",
        "TRANSPARENT_BG = False           # 透過背景（True推奨：背景素材として重ねやすい）\n",
        "BACKGROUND_COLOR = \"white\"       # 透過しない場合の背景色\n",
        "ALPHA_ON_SAVE = 200              # 0-255（背景素材として薄め推奨: 150〜220）。Noneで無効\n",
        "\n",
        "# レイアウト/語数\n",
        "MAX_WORDS = 200                  # 背景用途は少なめが上品（150〜250推奨）\n",
        "RANDOM_STATE = 42\n",
        "PREFER_HORIZONTAL = 0.95         # 横書き優先（背景用途は高め推奨）\n",
        "MIN_TOKEN_LEN = 2\n",
        "MIN_FREQUENCY = 2\n",
        "NGRAM_N = 1                      # 1:ユニグラム, 2:バイグラム, 3:トライグラム\n",
        "\n",
        "# 色付けモード：\"palette\" / \"colormap\" / \"custom\"\n",
        "COLOR_MODE = \"palette\"\n",
        "\n",
        "# カラーマップ名（COLOR_MODE=\"colormap\" のとき）\n",
        "COLORMAP_NAME = \"Set3\"\n",
        "\n",
        "# パレット（背景素材向けおすすめ例：ゴールド/ブルー/グレイ）\n",
        "# ゴールド調（アニバーサリー感）\n",
        "# PALETTE = [\"#C9A86A\", \"#D3BC8D\", \"#E6D6B8\", \"#F4EEDD\"]\n",
        "# ブルー調（学術・コーポレート）\n",
        "# PALETTE = [\"#0D47A1\", \"#1565C0\", \"#1E88E5\", \"#64B5F6\"]\n",
        "# グレイ（上品モノトーン）\n",
        "# PALETTE = [\"#BDBDBD\", \"#D4D4D4\", \"#E0E0E0\", \"#EEEEEE\"]\n",
        "PALETTE = [\"#C9A86A\", \"#D3BC8D\", \"#E6D6B8\", \"#F4EEDD\"]  # デフォルト：ゴールド系\n",
        "\n",
        "# エッジフェード（背景に馴染ませる）\n",
        "APPLY_EDGE_FADE = True\n",
        "EDGE_FADE_STRENGTH = 0.6         # 0〜1（0.5〜0.8 推奨）\n",
        "EDGE_FADE_SHAPE = \"radial\"       # \"radial\"（円形） / 将来拡張用\n",
        "\n",
        "# セーフテキスト帯（上に見出しを載せるための半透明帯）\n",
        "ADD_SAFE_TITLE_BAND = True\n",
        "BAND_HEIGHT_PX = 240\n",
        "BAND_COLOR = \"#FFFFFF\"\n",
        "BAND_ALPHA = 160\n",
        "BAND_POSITION = \"center\"         # \"top\" / \"center\" / \"bottom\"\n",
        "\n",
        "# フォント（\"auto\" 推奨：環境に応じて最適な日本語フォントを探索）\n",
        "FONT_PATH = \"auto\"\n",
        "FONT_PREFERRED_WEIGHT = \"Light\"  # \"Light\" / \"Regular\"（背景は細身推奨）\n",
        "\n",
        "# 追加ストップワード（プロジェクト固有の汎用語をノイズ除去）\n",
        "EXTRA_STOPWORDS = {\n",
        "    # 例: \"研究\", \"結果\", \"影響\", \"study\", \"result\"\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# 依存と環境（Colab自動インストール）\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import unicodedata\n",
        "import subprocess\n",
        "from collections import Counter\n",
        "from itertools import tee\n",
        "\n",
        "# Colab 検出\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def _ensure(cmd_list):\n",
        "    try:\n",
        "        subprocess.run(cmd_list, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    except Exception:\n",
        "        # サイレント失敗（ローカルJupyter等で権限なしの可能性を考慮）\n",
        "        pass\n",
        "\n",
        "# Colab では日本語フォントとライブラリを自動導入\n",
        "if IN_COLAB:\n",
        "    _ensure([\"bash\", \"-lc\", \"apt-get -y update >/dev/null 2>&1 || true\"])\n",
        "    _ensure([\"bash\", \"-lc\", \"apt-get -y install fonts-noto-cjk >/dev/null 2>&1 || true\"])\n",
        "    _ensure([\"bash\", \"-lc\", \"pip -q install wordcloud janome tinysegmenter >/dev/null 2>&1 || true\"])\n",
        "\n",
        "# ライブラリ読み込み\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# 形態素（日本語）\n",
        "try:\n",
        "    from janome.tokenizer import Tokenizer as JanomeTokenizer\n",
        "    _janome = JanomeTokenizer(wakati=False)\n",
        "except Exception:\n",
        "    _janome = None\n",
        "\n",
        "try:\n",
        "    from tinysegmenter import TinySegmenter\n",
        "    _tinyseg = TinySegmenter()\n",
        "except Exception:\n",
        "    _tinyseg = None\n",
        "\n",
        "# Colab の簡易アップロード\n",
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    _colab_files = files\n",
        "except Exception:\n",
        "    _colab_files = None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ユーティリティ（正規化・トークン化・n-gram）\n",
        "# ============================================================\n",
        "\n",
        "_CJK_RE = re.compile(r\"[\\u3040-\\u30FF\\u3400-\\u4DBF\\u4E00-\\u9FFF]\")\n",
        "_NUM_RE = re.compile(r\"^[0-9]+$\")\n",
        "_SYM_RE = re.compile(r\"^[_\\W]+$\", flags=re.UNICODE)\n",
        "_EN_TOKEN_RE = re.compile(r\"[A-Za-z][A-Za-z']+\")\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    t = unicodedata.normalize(\"NFKC\", text)\n",
        "    t = re.sub(r\"[\\u0000-\\u001F\\u007F\\u200B-\\u200F\\u202A-\\u202E]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "def contains_cjk(text: str) -> bool:\n",
        "    return bool(_CJK_RE.search(text))\n",
        "\n",
        "def english_tokens(text: str):\n",
        "    t = text.lower()\n",
        "    return _EN_TOKEN_RE.findall(t)\n",
        "\n",
        "def japanese_tokens(text: str):\n",
        "    # Janome（推奨）：名詞/動詞/形容詞の基本形で収集\n",
        "    if _janome is not None:\n",
        "        toks = []\n",
        "        for token in _janome.tokenize(text):\n",
        "            pos = token.part_of_speech.split(\",\")[0]\n",
        "            base = token.base_form if token.base_form != \"*\" else token.surface\n",
        "            if pos in (\"名詞\", \"動詞\", \"形容詞\"):\n",
        "                toks.append(base)\n",
        "        return toks\n",
        "    # TinySegmenter：フォールバック\n",
        "    if _tinyseg is not None:\n",
        "        return _tinyseg.tokenize(text)\n",
        "    # さらなるフォールバック：CJK連続抽出\n",
        "    return re.findall(r\"[一-龥々〆ヵヶぁ-んァ-ヴー]+\", text)\n",
        "\n",
        "def make_ngrams(tokens, n=2):\n",
        "    if n <= 1:\n",
        "        return tokens\n",
        "    iters = tee(tokens, n)\n",
        "    for i, it in enumerate(iters):\n",
        "        for _ in range(i):\n",
        "            next(it, None)\n",
        "    return [\"_\".join(t) for t in zip(*iters)]\n",
        "\n",
        "def load_lines(path: str):\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                yield line\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ストップワード（英・日）\n",
        "# ============================================================\n",
        "\n",
        "EN_STOP = {\n",
        "    \"a\",\"an\",\"the\",\"and\",\"or\",\"but\",\"if\",\"then\",\"else\",\"when\",\"while\",\"for\",\"of\",\"in\",\"on\",\"at\",\n",
        "    \"to\",\"from\",\"by\",\"with\",\"without\",\"about\",\"across\",\"after\",\"before\",\"during\",\"within\",\"between\",\n",
        "    \"is\",\"am\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\n",
        "    \"having\",\"can\",\"could\",\"may\",\"might\",\"must\",\"should\",\"would\",\"will\",\"shall\",\n",
        "    \"this\",\"that\",\"these\",\"those\",\"it\",\"its\",\"as\",\"not\",\"no\",\"yes\",\"we\",\"you\",\"he\",\"she\",\"they\",\"them\",\n",
        "    \"their\",\"there\",\"here\",\"such\",\"than\",\"via\",\"per\",\"etc\",\"i\",\"our\",\"us\",\"your\",\"yours\",\"his\",\"her\",\n",
        "    \"into\",\"out\",\"over\",\"under\",\"again\",\"new\",\"based\",\"using\",\"use\",\"used\",\"study\",\"analysis\",\"results\",\n",
        "    \"result\",\"method\",\"methods\",\"approach\",\"approaches\",\"paper\",\"article\",\"report\",\"case\",\"cases\",\n",
        "    \"effect\",\"effects\",\"evidence\",\"evaluation\",\"overview\",\"review\",\"reviews\",\"systematic\",\"meta\",\n",
        "    \"toward\",\"towards\",\"impact\",\"impacts\",\"improving\",\"improvement\",\"improve\",\n",
        "    \"model\",\"models\",\"modelling\",\"modeling\",\"data\",\"dataset\",\"datasets\",\"large\",\"small\",\"novel\",\n",
        "    \"among\",\"across\",\"more\",\"most\",\"less\",\"least\"\n",
        "}\n",
        "\n",
        "JA_STOP = {\n",
        "    \"こと\",\"もの\",\"ところ\",\"ため\",\"よう\",\"られ\",\"れる\",\"ない\",\"ある\",\"いる\",\"おり\",\"なる\",\"する\",\"できる\",\n",
        "    \"的\",\"的な\",\"的に\",\"における\",\"において\",\"及び\",\"および\",\"ならびに\",\n",
        "    \"これ\",\"それ\",\"あれ\",\"どれ\",\"ここ\",\"そこ\",\"あそこ\",\"どこ\",\"この\",\"その\",\"あの\",\"どの\",\n",
        "    \"そして\",\"また\",\"さらに\",\"しかし\",\"一方\",\"など\",\"等\",\"等の\",\"等を\",\"等に\",\"等で\",\"等と\",\n",
        "    \"例\",\"場合\",\"結果\",\"研究\",\"検討\",\"報告\",\"考察\",\"課題\",\"手法\",\"方法\",\"比較\",\n",
        "    \"影響\",\"実験\",\"解析\",\"分析\",\"評価\",\"事例\",\"概要\",\"総説\",\"序論\",\"序説\",\"序\",\"序文\",\"序章\",\n",
        "    \"新た\",\"新しい\",\"新規\",\"一\",\"二\",\"三\",\"四\",\"五\",\"六\",\"七\",\"八\",\"九\",\"十\",\"第\",\"年\",\"月\",\"日\",\n",
        "}\n",
        "\n",
        "STOPWORDS = set(EN_STOP) | set(JA_STOP) | set(EXTRA_STOPWORDS)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# フォント検出（日本語）：\"Light\" を優先して背景向けの軽やかさを出す\n",
        "# ============================================================\n",
        "\n",
        "def find_japanese_font(preferred_weight: str = \"Light\") -> str | None:\n",
        "    \"\"\"\n",
        "    候補：\n",
        "      - Noto Sans CJK JP / Source Han Sans / IPA系 / Yu Gothic / Meiryo / Hiragino\n",
        "    TTC/OTF/TTF の中から、希望ウェイトを優先して選択します。\n",
        "    \"\"\"\n",
        "    if isinstance(FONT_PATH, str) and FONT_PATH not in (None, \"\", \"auto\"):\n",
        "        return FONT_PATH if os.path.exists(FONT_PATH) else None\n",
        "\n",
        "    # Colab の典型パス\n",
        "    common_paths = [\n",
        "        \"/usr/share/fonts/opentype/noto/NotoSansCJKjp-Light.otf\",\n",
        "        \"/usr/share/fonts/opentype/noto/NotoSansCJKjp-Regular.otf\",\n",
        "        \"/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc\",\n",
        "    ]\n",
        "    for p in common_paths:\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "\n",
        "    # matplotlib font manager から探索\n",
        "    candidates = [\n",
        "        \"Noto Sans CJK JP\", \"Noto Sans JP\", \"Source Han Sans\", \"Source Han Serif\",\n",
        "        \"Noto Serif CJK JP\", \"IPAGothic\", \"IPAexGothic\", \"IPAMincho\", \"IPAexMincho\",\n",
        "        \"Yu Gothic\", \"YuGothic\", \"Meiryo\", \"MS Gothic\", \"MS Mincho\",\n",
        "        \"Hiragino Sans\", \"Hiragino Kaku Gothic ProN\", \"Hiragino Mincho ProN\",\n",
        "        \"ヒラギノ角ゴ ProN W3\"\n",
        "    ]\n",
        "    weight_keys = {\n",
        "        \"Light\": [\"light\", \"demilight\", \"ultralight\", \"extra light\"],\n",
        "        \"Regular\": [\"regular\", \"book\", \"normal\"]\n",
        "    }\n",
        "    weight_list = weight_keys.get(preferred_weight, []) + weight_keys[\"Regular\"]\n",
        "\n",
        "    # まず family 名で絞り、ウェイトを優先\n",
        "    fonts = getattr(fm, \"fontManager\", None)\n",
        "    ttflist = fonts.ttflist if fonts else []\n",
        "    # 候補だけ抽出\n",
        "    pool = [f for f in ttflist if any(c.lower() in getattr(f, \"name\",\"\").lower() for c in candidates)]\n",
        "    # ウェイト優先で並べ替え\n",
        "    def score(fi):\n",
        "        fname = os.path.basename(getattr(fi, \"fname\", \"\")).lower()\n",
        "        for i, key in enumerate(weight_list):\n",
        "            if key in fname:\n",
        "                return i\n",
        "        return 999\n",
        "    pool.sort(key=score)\n",
        "    for fi in pool:\n",
        "        path = getattr(fi, \"fname\", \"\")\n",
        "        if path and os.path.exists(path):\n",
        "            return path\n",
        "\n",
        "    # ファイル名ベース fallback\n",
        "    sys_fonts = fm.findSystemFonts() if hasattr(fm, \"findSystemFonts\") else []\n",
        "    for c in candidates:\n",
        "        for p in sys_fonts:\n",
        "            if c.replace(\" \", \"\").lower() in os.path.basename(p).replace(\" \", \"\").lower():\n",
        "                return p if os.path.exists(p) else None\n",
        "    return None\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# トークン化・頻度算出\n",
        "# ============================================================\n",
        "\n",
        "def preprocess_and_tokenize(line: str):\n",
        "    text = normalize_text(line)\n",
        "    en = english_tokens(text)\n",
        "    ja = japanese_tokens(text) if contains_cjk(text) else []\n",
        "    tokens = en + ja\n",
        "\n",
        "    clean = []\n",
        "    for tok in tokens:\n",
        "        tok = tok.strip()\n",
        "        if not tok:\n",
        "            continue\n",
        "        if _NUM_RE.fullmatch(tok):\n",
        "            continue\n",
        "        if _SYM_RE.fullmatch(tok):\n",
        "            continue\n",
        "        if len(tok) < MIN_TOKEN_LEN:\n",
        "            continue\n",
        "        clean.append(tok)\n",
        "    return clean\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 配色 color_func：palette / colormap / custom（日本語=青, 英語=橙 など）\n",
        "# ============================================================\n",
        "\n",
        "def make_palette_color_func(palette):\n",
        "    def _cf(word, font_size, position, orientation, random_state=None, **kwargs):\n",
        "        idx = abs(hash(word)) % len(palette)  # 安定割当（同語→同色）\n",
        "        return palette[idx]\n",
        "    return _cf\n",
        "\n",
        "def make_colormap_color_func(cmap_name):\n",
        "    cmap = mpl.cm.get_cmap(cmap_name)\n",
        "    def _cf(word, font_size, position, orientation, random_state=None, **kwargs):\n",
        "        r = abs(hash(word)) % 10_000\n",
        "        color = cmap((r / 10_000))\n",
        "        r_, g_, b_, _ = [int(255*x) for x in color]\n",
        "        return f\"rgb({r_}, {g_}, {b_})\"\n",
        "    return _cf\n",
        "\n",
        "def make_custom_color_func(freq_counter):\n",
        "    # 例：日本語（青系）/ 英語（オレンジ系）、頻度で濃淡\n",
        "    ja_palette = [\"#1565C0\", \"#1E88E5\", \"#42A5F5\", \"#90CAF9\"]\n",
        "    en_palette = [\"#E65100\", \"#FB8C00\", \"#FFB74D\", \"#FFE0B2\"]\n",
        "    max_f = max(freq_counter.values()) if freq_counter else 1\n",
        "\n",
        "    def _cf(word, font_size, position, orientation, random_state=None, **kwargs):\n",
        "        palette = ja_palette if _CJK_RE.search(word) else en_palette\n",
        "        f = freq_counter.get(word, 1)\n",
        "        tier = int((1 - (f / max_f)) * (len(palette) - 1))  # 高頻度ほど濃い\n",
        "        tier = max(0, min(tier, len(palette)-1))\n",
        "        return palette[tier]\n",
        "    return _cf\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 後処理（透明化、エッジフェード、セーフテキスト帯）\n",
        "# ============================================================\n",
        "\n",
        "def ensure_rgba(img: Image.Image) -> Image.Image:\n",
        "    return img.convert(\"RGBA\") if img.mode != \"RGBA\" else img\n",
        "\n",
        "def apply_uniform_alpha(img: Image.Image, alpha: int) -> Image.Image:\n",
        "    \"\"\"画像全体の透明度を一律に下げる（背景素材向け）。\"\"\"\n",
        "    img = ensure_rgba(img)\n",
        "    r, g, b, a = img.split()\n",
        "    a = a.point(lambda v: v * (alpha / 255.0))\n",
        "    return Image.merge(\"RGBA\", (r, g, b, a))\n",
        "\n",
        "def apply_edge_fade(img: Image.Image, strength: float = 0.6, shape: str = \"radial\") -> Image.Image:\n",
        "    \"\"\"四辺をフェードアウトさせ、周囲の要素と馴染ませる。strength: 0〜1\"\"\"\n",
        "    img = ensure_rgba(img)\n",
        "    w, h = img.size\n",
        "    y, x = np.ogrid[:h, :w]\n",
        "    cx, cy = w / 2.0, h / 2.0\n",
        "    # 距離正規化（0中心→1端）\n",
        "    dist = np.sqrt(((x - cx) / (w / 2))**2 + ((y - cy) / (h / 2))**2)\n",
        "    dist = np.clip(dist, 0, 1)\n",
        "    # エッジで α を下げるマスク\n",
        "    # 1 - (dist^p)*strength で端を弱く\n",
        "    p = 2.0\n",
        "    mask = (1.0 - (dist ** p) * strength)\n",
        "    mask = np.clip(mask, 0, 1)\n",
        "    alpha = (mask * 255).astype(np.uint8)\n",
        "\n",
        "    r, g, b, a = img.split()\n",
        "    # 既存アルファと合成（小さい方を採用）\n",
        "    a_np = np.minimum(np.array(a), alpha)\n",
        "    a_new = Image.fromarray(a_np, mode=\"L\")\n",
        "    return Image.merge(\"RGBA\", (r, g, b, a_new))\n",
        "\n",
        "def add_safe_title_band(img: Image.Image, band_h: int = 240, color: str = \"#FFFFFF\",\n",
        "                        alpha: int = 160, position: str = \"center\") -> Image.Image:\n",
        "    \"\"\"前景テキストの可読性を上げる半透明帯を敷く（top/center/bottom）。\"\"\"\n",
        "    img = ensure_rgba(img)\n",
        "    w, h = img.size\n",
        "    y0, y1 = {\n",
        "        \"top\": (0, band_h),\n",
        "        \"center\": ((h - band_h)//2, (h + band_h)//2),\n",
        "        \"bottom\": (h - band_h, h)\n",
        "    }.get(position, ((h - band_h)//2, (h + band_h)//2))\n",
        "\n",
        "    overlay = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
        "    draw = ImageDraw.Draw(overlay)\n",
        "    # color(hex) + alpha を RGBA に\n",
        "    color = color.lstrip(\"#\")\n",
        "    r = int(color[0:2], 16)\n",
        "    g = int(color[2:4], 16)\n",
        "    b = int(color[4:6], 16)\n",
        "    draw.rectangle([0, y0, w, y1], fill=(r, g, b, alpha))\n",
        "    return Image.alpha_composite(img, overlay)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# メイン：頻度計算→WordCloud生成→後処理→保存\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "    # プリセット適用\n",
        "    global WC_WIDTH, WC_HEIGHT\n",
        "    if PRESET == \"hero\":\n",
        "        WC_WIDTH, WC_HEIGHT = 2400, 1200\n",
        "    elif PRESET == \"banner\":\n",
        "        WC_WIDTH, WC_HEIGHT = 2400, 800\n",
        "    elif PRESET == \"strip\":\n",
        "        WC_WIDTH, WC_HEIGHT = 1600, 300\n",
        "\n",
        "    # 入力ファイルが無い場合、Colab ならアップロード促進\n",
        "    if not os.path.exists(INPUT_FILE) and IN_COLAB and _colab_files is not None:\n",
        "        print(f\"'{INPUT_FILE}' が見つかりません。ダイアログからアップロードしてください。\")\n",
        "        uploaded = _colab_files.upload()\n",
        "        if INPUT_FILE not in uploaded and uploaded:\n",
        "            alt = next(iter(uploaded.keys()))\n",
        "            os.rename(alt, INPUT_FILE)\n",
        "            print(f\"アップロードされた '{alt}' を '{INPUT_FILE}' として使用します。\")\n",
        "\n",
        "    if not os.path.exists(INPUT_FILE):\n",
        "        raise FileNotFoundError(f\"{INPUT_FILE} が見つかりません。パスを確認してください。\")\n",
        "\n",
        "    # 頻度集計\n",
        "    freq = Counter()\n",
        "    for line in load_lines(INPUT_FILE):\n",
        "        tokens = preprocess_and_tokenize(line)\n",
        "        if NGRAM_N and NGRAM_N > 1:\n",
        "            tokens = make_ngrams(tokens, n=NGRAM_N)\n",
        "        tokens = [t for t in tokens if t not in STOPWORDS]\n",
        "        freq.update(tokens)\n",
        "\n",
        "    if MIN_FREQUENCY > 1:\n",
        "        freq = Counter({k: v for k, v in freq.items() if v >= MIN_FREQUENCY})\n",
        "\n",
        "    if not freq:\n",
        "        raise ValueError(\"有効なトークンが得られませんでした。STOPWORDS/MIN_TOKEN_LEN/MIN_FREQUENCY を見直してください。\")\n",
        "\n",
        "    # フォント決定\n",
        "    font_path = find_japanese_font(preferred_weight=FONT_PREFERRED_WEIGHT)\n",
        "    if font_path is None:\n",
        "        print(\"警告: 日本語フォントを自動検出できませんでした。FONT_PATH に日本語フォントのパスを設定してください。\")\n",
        "\n",
        "    # color_func 決定\n",
        "    if COLOR_MODE == \"palette\":\n",
        "        color_func = make_palette_color_func(PALETTE)\n",
        "    elif COLOR_MODE == \"colormap\":\n",
        "        color_func = make_colormap_color_func(COLORMAP_NAME)\n",
        "    elif COLOR_MODE == \"custom\":\n",
        "        color_func = make_custom_color_func(freq)\n",
        "    else:\n",
        "        color_func = None\n",
        "\n",
        "    # 透過背景の指定（WordCloud 自体の描画設定）\n",
        "    wc_kwargs = dict(\n",
        "        width=WC_WIDTH,\n",
        "        height=WC_HEIGHT,\n",
        "        max_words=MAX_WORDS,\n",
        "        font_path=font_path,\n",
        "        prefer_horizontal=PREFER_HORIZONTAL,\n",
        "        random_state=RANDOM_STATE,\n",
        "        collocations=False\n",
        "    )\n",
        "    if TRANSPARENT_BG:\n",
        "        wc_kwargs.update(dict(mode=\"RGBA\", background_color=None))\n",
        "    else:\n",
        "        wc_kwargs.update(dict(background_color=BACKGROUND_COLOR))\n",
        "\n",
        "    wc = WordCloud(**wc_kwargs).generate_from_frequencies(freq)\n",
        "\n",
        "    # 配色（レイアウトを固定したまま色だけ変更）\n",
        "    if color_func is not None:\n",
        "        wc.recolor(color_func=color_func, random_state=RANDOM_STATE)\n",
        "\n",
        "    # 保存：基本版\n",
        "    wc.to_file(OUTPUT_PNG)\n",
        "    print(f\"[OK] 保存: {OUTPUT_PNG}\")\n",
        "\n",
        "    # 画像ロード（後処理のため）\n",
        "    base = Image.open(OUTPUT_PNG)\n",
        "    base = ensure_rgba(base)\n",
        "\n",
        "    # 透過版（TRANSPARENT_BG=False でも ALPHA_ON_SAVE が設定されていれば RGBA 出力）\n",
        "    transparent = base.copy()\n",
        "    if ALPHA_ON_SAVE is not None:\n",
        "        transparent = apply_uniform_alpha(transparent, ALPHA_ON_SAVE)\n",
        "    transparent.save(\"wordcloud_transparent.png\")\n",
        "    print(f\"[OK] 保存: wordcloud_transparent.png\")\n",
        "\n",
        "    # エッジフェード版\n",
        "    if APPLY_EDGE_FADE:\n",
        "        faded = apply_edge_fade(transparent, strength=EDGE_FADE_STRENGTH, shape=EDGE_FADE_SHAPE)\n",
        "        faded.save(\"wordcloud_faded.png\")\n",
        "        print(f\"[OK] 保存: wordcloud_faded.png\")\n",
        "        working = faded\n",
        "    else:\n",
        "        working = transparent\n",
        "\n",
        "    # セーフテキスト帯つき版（見出しを上に重ねる背景として最適）\n",
        "    if ADD_SAFE_TITLE_BAND:\n",
        "        banded = add_safe_title_band(\n",
        "            working,\n",
        "            band_h=BAND_HEIGHT_PX,\n",
        "            color=BAND_COLOR,\n",
        "            alpha=BAND_ALPHA,\n",
        "            position=BAND_POSITION\n",
        "        )\n",
        "        banded.save(\"wordcloud_with_band.png\")\n",
        "        print(f\"[OK] 保存: wordcloud_with_band.png\")\n",
        "\n",
        "    # トップ語表示\n",
        "    print(\"\\n上位20語:\")\n",
        "    for w, c in freq.most_common(20):\n",
        "        print(f\"{w}\\t{c}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "id": "4jXNn0e4o7CN"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}